Title: Inter-Coder Agreement for Computational Linguistics

Source: crossref
Authors: Ron Artstein, Massimo Poesio
Year: 2008
URL: https://doi.org/10.1162/coli.07-034-r2

Abstract:
 This article is a survey of methods for measuring agreement among corpus annotators. It exposes the mathematics and underlying assumptions of agreement coefficients, covering Krippendorff's alpha as well as Scott's pi and Cohen's kappa; discusses the use of coefficients in several annotation tasks; and argues that weighted, alpha-like coefficients, traditionally less used than kappa-like measures in computational linguistics, may be more appropriate for many corpus annotation tasksâ€”but that their use makes the interpretation of the value of the coefficient even harder. 
