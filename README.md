# ğŸ” PLAUGE - Plagiarism Detection System

A comprehensive plagiarism detection system using TF-IDF and cosine similarity, with a large corpus of academic papers from multiple sources.

## ğŸ“ Project Structure

```
PLAUGE/
â”œâ”€â”€ main.py                         # ğŸš€ Main entry point
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ backend/                        # ğŸ§  Backend ML Models & Logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ core/                       # Core ML algorithms
â”‚   â”‚   â”œâ”€â”€ plagiarism_detector.py  # Main plagiarism detection engine
â”‚   â”‚   â”œâ”€â”€ check_against_corpus.py # Check papers against corpus
â”‚   â”‚   â””â”€â”€ check_my_documents.py   # Check user documents
â”‚   â”œâ”€â”€ api/                        # REST API endpoints (future)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ database/                   # Database management
â”‚   â”‚   â”œâ”€â”€ corpus_builder.py       # Multi-source corpus downloader
â”‚   â”‚   â””â”€â”€ corpus_database.db      # SQLite database (575+ papers)
â”‚   â””â”€â”€ utils/                      # Utility functions
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ corpus/                         # ğŸ“š Academic Papers Corpus (603 papers)
â”‚   â”œâ”€â”€ machine_learning/           # 65 papers
â”‚   â”œâ”€â”€ deep_learning/              # 43 papers
â”‚   â”œâ”€â”€ nlp/                        # 29 papers
â”‚   â”œâ”€â”€ plagiarism_detection/       # 34 papers (directly relevant!)
â”‚   â”œâ”€â”€ text_similarity/            # 41 papers
â”‚   â”œâ”€â”€ information_retrieval/      # 20 papers
â”‚   â”œâ”€â”€ ai_general/                 # 25 papers
â”‚   â”œâ”€â”€ computer_vision/            # 28 papers
â”‚   â”œâ”€â”€ transformers/               # 39 papers
â”‚   â”œâ”€â”€ reinforcement_learning/     # 22 papers
â”‚   â”œâ”€â”€ data_science/               # 10 papers
â”‚   â”œâ”€â”€ computational_linguistics/  # 14 papers
â”‚   â””â”€â”€ other/                      # 233 papers
â”‚
â”œâ”€â”€ config/                         # âš™ï¸ Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py                 # App settings & thresholds
â”‚
â”œâ”€â”€ scripts/                        # ğŸ”§ Utility Scripts
â”‚   â”œâ”€â”€ download_corpus.py          # Download from arXiv
â”‚   â””â”€â”€ organize_project.py         # Project organization tool
â”‚
â”œâ”€â”€ docs/                           # ğŸ“„ Documentation
â”‚   â””â”€â”€ DOCUMENTATION.txt           # Detailed documentation
â”‚
â”œâ”€â”€ submit/                         # ğŸ“ Papers to Check
â”‚   â””â”€â”€ (place your papers here)
â”‚
â”œâ”€â”€ documents/                      # ğŸ“‚ User Documents
â”‚
â””â”€â”€ frontend/                       # ğŸŒ Web Interface (future)
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Run Commands

```bash
# Show help
python main.py

# Check a paper for plagiarism
python main.py check

# Manage corpus (download more papers)
python main.py corpus

# Run demo with sample documents
python main.py demo
```

## ğŸ“Š Corpus Statistics

| Category | Papers | Description |
|----------|--------|-------------|
| **Machine Learning** | 65 | ML algorithms, sklearn, classification |
| **Deep Learning** | 43 | Neural networks, CNNs, RNNs |
| **NLP** | 29 | Natural language processing |
| **Plagiarism Detection** | 34 | Directly relevant research! |
| **Text Similarity** | 41 | Cosine, Jaccard, semantic similarity |
| **Transformers** | 39 | BERT, GPT, attention mechanisms |
| **Information Retrieval** | 20 | Search, ranking, indexing |
| **Computer Vision** | 28 | Image processing, object detection |
| **AI General** | 25 | General artificial intelligence |
| **Reinforcement Learning** | 22 | Q-learning, policy gradients |
| **Data Science** | 10 | Analytics, visualization |
| **Computational Linguistics** | 14 | Syntax, semantics, morphology |
| **Other** | 233 | Miscellaneous academic papers |
| **Total** | **603** | |

### Data Sources
- ğŸ“š **arXiv** - Open-access preprints
- ğŸ“– **Semantic Scholar** - AI-curated database
- ğŸ”— **CrossRef** - Published research with DOIs
- ğŸŒ **OpenAlex** - Open academic catalog

## ğŸ§  How It Works

### 1. Text Preprocessing
- Lowercase conversion
- Punctuation removal
- Tokenization
- Stopword removal
- Lemmatization

### 2. Feature Extraction
- TF-IDF vectorization
- N-gram support (unigrams + bigrams)
- Max 5000 features

### 3. Similarity Calculation
- Cosine similarity between document vectors
- Generates similarity matrix

### 4. Plagiarism Classification
| Similarity | Level | Color |
|------------|-------|-------|
| â‰¥ 80% | ğŸ”´ High Plagiarism | Red |
| 50-79% | ğŸŸ¡ Medium Plagiarism | Yellow |
| < 50% | ğŸŸ¢ Low Plagiarism | Green |

## ğŸ“¥ Building Your Corpus

### Quick Download (Recommended Topics)
```bash
python main.py corpus
# Select option 1 for quick download
```

### Custom Topic Download
```bash
# From command line
python backend/database/corpus_builder.py --download "specific topic" 50

# Or interactive mode
python main.py corpus
# Select option 2
```

### View Corpus Statistics
```bash
python backend/database/corpus_builder.py --stats
```

## ğŸ” Checking Documents

### 1. Place your paper in `submit/` folder
```
submit/
â””â”€â”€ my_paper.txt
```

### 2. Run the checker
```bash
python main.py check
```

### 3. View Results
The system will compare your paper against all 603 corpus papers and show:
- Overall highest match percentage
- Detailed matches sorted by similarity
- Plagiarism level classification

## ğŸ“¦ Dependencies

```
nltk>=3.8
scikit-learn>=1.3
numpy>=1.24
```

## ğŸ”® Future Enhancements

- [ ] Web interface (frontend/)
- [ ] REST API (backend/api/)
- [ ] Real-time document monitoring
- [ ] PDF/DOCX support
- [ ] Citation detection
- [ ] Paraphrase detection with BERT
- [ ] Report generation (PDF)

## ğŸ“„ License

MIT License

---

**Built with â¤ï¸ using Python, NLTK, and Scikit-learn**